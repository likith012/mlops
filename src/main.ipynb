{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = os.path.join(os.getcwd(), '../data/spam.csv')\n",
    "df = pd.read_csv(csv_path, delimiter=',', encoding='latin-1')\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
    "df.rename(columns={'v1':'label', 'v2':'text'}, inplace=True)\n",
    "df['spam']=df['label'].apply(lambda x: 0 if x=='spam' else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list(df['text']), list(df['spam']), test_size=0.2, stratify=df['spam'], random_state=42)\n",
    "\n",
    "VOCAB_SIZE = 1000\n",
    "MAX_LEN = 150\n",
    "EMBEDDING_DIM = 64\n",
    "\n",
    "tokenizer=Tokenizer(num_words=VOCAB_SIZE,oov_token=\"SPL\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_seq=tokenizer.texts_to_sequences(X_train)\n",
    "train_pad=pad_sequences(train_seq, maxlen=MAX_LEN, truncating=\"post\")\n",
    "\n",
    "test_seq=tokenizer.texts_to_sequences(X_test)\n",
    "test_pad=pad_sequences(test_seq,maxlen=MAX_LEN, truncating=\"post\")\n",
    "\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 150)]             0         \n",
      "                                                                 \n",
      " embedding_6 (Embedding)     (None, 150, 64)           64000     \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 150, 128)         66048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 128)              98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 233,025\n",
      "Trainable params: 233,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "140/140 [==============================] - 42s 228ms/step - loss: 0.1862 - accuracy: 0.9379 - val_loss: 0.0705 - val_accuracy: 0.9812\n",
      "Epoch 2/30\n",
      "140/140 [==============================] - 29s 209ms/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 0.0699 - val_accuracy: 0.9848\n",
      "Epoch 3/30\n",
      "140/140 [==============================] - 28s 201ms/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.0675 - val_accuracy: 0.9857\n",
      "Epoch 4/30\n",
      "140/140 [==============================] - 28s 201ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0796 - val_accuracy: 0.9776\n",
      "Epoch 5/30\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.0802 - val_accuracy: 0.9848\n",
      "Epoch 6/30\n",
      "140/140 [==============================] - 28s 202ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0907 - val_accuracy: 0.9839\n",
      "Epoch 7/30\n",
      "140/140 [==============================] - 28s 203ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0900 - val_accuracy: 0.9830\n",
      "Epoch 8/30\n",
      "140/140 [==============================] - 29s 205ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.1190 - val_accuracy: 0.9839\n",
      "Epoch 9/30\n",
      "140/140 [==============================] - 28s 202ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.1160 - val_accuracy: 0.9857\n",
      "Epoch 10/30\n",
      "140/140 [==============================] - 28s 202ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.0831 - val_accuracy: 0.9865\n",
      "Epoch 11/30\n",
      "140/140 [==============================] - 27s 192ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0984 - val_accuracy: 0.9830\n",
      "Epoch 12/30\n",
      "140/140 [==============================] - 27s 195ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.0838 - val_accuracy: 0.9803\n",
      "Epoch 13/30\n",
      "140/140 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998Restoring model weights from the end of the best epoch: 3.\n",
      "140/140 [==============================] - 28s 199ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1178 - val_accuracy: 0.9803\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(name='inputs', shape=[MAX_LEN])\n",
    "x = Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN)(inputs)\n",
    "x = Bidirectional(LSTM(units=64, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(units=64))(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "early_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "history = model.fit(train_pad, y_train, epochs=30, validation_data=(test_pad, y_test), callbacks=[early_callback], batch_size=32, use_multiprocessing=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(os.getcwd(), '../checkpoints')\n",
    "\n",
    "json_config = model.to_json()\n",
    "with open(os.path.join(save_path, 'model_config.json'), 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "    \n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open(os.path.join(save_path, 'tokenizer.json'), 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(tokenizer_json)\n",
    "        \n",
    "model.save_weights(os.path.join(save_path, 'best_weights.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75888df319af0084e738a1edba5a2992cdad86ea2bc59cb88e480e9f6b0006c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
